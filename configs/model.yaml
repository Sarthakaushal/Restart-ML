# create config file for training simple GAN
simple_gan:
  # Model Params
  model_type: simple_gan
  batch_size: 64
  z_dim: [1, 28, 28]
  gen_hidden_dim: [128, 256, 512, 1024]
  disc_hidden_dim: [512, 256]
  data_dim: 784
  
  # Accelerator
  device: mps
  
  # Training params
  num_epochs: 101

  # Mlflow Tracking
  tracking: True

  # Logging Params
  output_dir: data/gan_generated_images/
  logging_freq: 10
  model_save_dir: model_dump/simple_gans
  #optimizer params
  # Todo : Extend the optimizer to include other optimizers
  g_optimizer : Adam # or "Adam"
  g_learning_rate: 0.0002
  g_betas_min: 0.5
  g_betas_max: 0.999
  d_optimizer : Adam # or "Adam"
  d_learning_rate: 0.0002
  d_betas_min: 0.5
  d_betas_max: 0.999
  disc_train_skip_freq: 2
  # Gradient clipping
  max_grad_norm: 1.0  # Maximum norm of gradients


# dcgan:
#   # Model Params
#   batch_size: 512
#   z_dim: [100,1,1]
#   gen_hidden_dim: [8, 16]
#   disc_hidden_dim: [8, 16]
#   # data_dim: 784
  
#   # Accelerator
#   device: mps
  
#   # Training params
#   num_epochs: 101

#   # Mlflow Tracking
#   tracking: True

#   # Logging Params
#   output_dir: data/gan_generated_images/
#   logging_freq: 10
#   model_save_dir: model_dump/dcgans
#   #optimizer params
#   # Todo : Extend the optimizer to include other optimizers
#   g_optimizer : Adam # or "Adam"
#   g_learning_rate: 0.0002
#   g_betas_min: 0.5
#   g_betas_max: 0.999
#   d_optimizer : Adam # or "Adam"
#   d_learning_rate: 0.0002
#   d_betas_min: 0.5
#   d_betas_max: 0.999
#   disc_train_skip_freq: 1
